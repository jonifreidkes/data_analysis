{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Exploring Hacker News posts\n",
    "\n",
    "## Introduction\n",
    "In this project, we'll work with a data set of submissions to popular technology site [Hacker News](https://news.ycombinator.com/). It is a site started by the startup incubator [Y Combinator](https://www.ycombinator.com/), where user-submitted stories (known as \"posts\") are voted and commented upon, similar to reddit. Hacker News is extremely popular in technology and startup circles, and posts that make it to the top of Hacker News' listings can get hundreds of thousands of visitors as a result.\n",
    "\n",
    "\n",
    "## Data set\n",
    "The data set used is [available](https://www.kaggle.com/hacker-news/hacker-news-posts), and it has been reduced to approximately 20 k rows by removing all submissions that did not receive any comments, and then randomly sampling from the remaining submissions.\n",
    "\n",
    "The columns are:\n",
    "\n",
    "|  Column name |                Description                |\n",
    "|:------------:|:-----------------------------------------:|\n",
    "|      id      | Post's unique identifier from Hacker News |\n",
    "|     title    |             Title of the post             |\n",
    "|      url     |      The URL that the posts links to      |\n",
    "|  num_points  |   The number of points the post acquired  |\n",
    "| num_comments |       Number of comments on the post      |\n",
    "|    author    |     Username of who submitted the post    |\n",
    "|  created_at  |   Date and time of the post's submission  |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "We're specifically interested in posts whose titles begin with either _Ask HN_ or _Show HN_. Users submit those posts to ask the Hacker News community a specific question.\n",
    "\n",
    "\n",
    "We'll compare these two types of posts to determine the following:\n",
    "\n",
    "- Do _Ask HN_ or _Show HN_ receive more comments on average?\n",
    "- Do posts created at a certain time receive more comments on average?\n",
    "\n",
    "We can see some rows of the data set below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['12579008', 'You have two days to comment if you want stem cells to be classified as your own', 'http://www.regulations.gov/document?D=FDA-2015-D-3719-0018', '1', '0', 'altstar', '9/26/2016 3:26']\n\n\n['12579005', 'SQLAR  the SQLite Archiver', 'https://www.sqlite.org/sqlar/doc/trunk/README.md', '1', '0', 'blacksqr', '9/26/2016 3:24']\n\n\n['12578997', 'What if we just printed a flatscreen television on the side of our boxes?', 'https://medium.com/vanmoof/our-secrets-out-f21c1f03fdc8#.ietxmez43', '1', '0', 'pavel_lishin', '9/26/2016 3:19']\n\n\n['12578989', 'algorithmic music', 'http://cacm.acm.org/magazines/2011/7/109891-algorithmic-composition/fulltext', '1', '0', 'poindontcare', '9/26/2016 3:16']\n\n\n['12578979', 'How the Data Vault Enables the Next-Gen Data Warehouse and Data Lake', 'https://www.talend.com/blog/2016/05/12/talend-and-Â\\x93the-data-vaultÂ\\x94', '1', '0', 'markgainor1', '9/26/2016 3:14']\n"
     ]
    }
   ],
   "source": [
    "from csv import reader\n",
    "\n",
    "file = open('hacker_news.csv')\n",
    "read_file = reader(file)\n",
    "hn = list(read_file)\n",
    "headers = hn[0]\n",
    "hn = hn[1:]\n",
    "print(hn[0])\n",
    "print('\\n')\n",
    "print(hn[1])\n",
    "print('\\n')\n",
    "print(hn[2])\n",
    "print('\\n')\n",
    "print(hn[3])\n",
    "print('\\n')\n",
    "print(hn[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we can observe the headers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n"
     ]
    }
   ],
   "source": [
    "print(headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Ask HN and Show HN Posts\n",
    "\n",
    "Now we will filter the data set into 3 lists:\n",
    "- ask_posts: Contains _Ask HN_ posts\n",
    "- show_posts: Contains _Show HN_ posts\n",
    "- other_posts: Contains the remaining posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total of Ask HN posts: 9139\nTotal of Show HN posts: 10158\nTotal of other posts: 273822\n"
     ]
    }
   ],
   "source": [
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "for post in hn:\n",
    "    tit = post[1]\n",
    "    title = tit.lower() #To avoid capitalization problems\n",
    "    if title.startswith('ask hn'):\n",
    "        ask_posts.append(post)\n",
    "    elif title.startswith('show hn'):\n",
    "        show_posts.append(post)\n",
    "    else:\n",
    "        other_posts.append(post)\n",
    "print('Total of Ask HN posts: ' + str(len(ask_posts)))\n",
    "print('Total of Show HN posts: ' + str(len(show_posts)))\n",
    "print('Total of other posts: ' + str(len(other_posts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can calculate the total of comments for each list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Average comments for Ask HN posts is: 10\nAverage comments for Show HN posts is: 5\nAverage comments for other posts is: 6\n"
     ]
    }
   ],
   "source": [
    "total_ask_comments = 0\n",
    "for post in ask_posts:\n",
    "    num_comments = int(post[4])\n",
    "    total_ask_comments += num_comments\n",
    "avg_ask_comments = round(total_ask_comments / len(ask_posts))\n",
    "\n",
    "total_show_comments = 0\n",
    "for post in show_posts:\n",
    "    num_comments = int(post[4])\n",
    "    total_show_comments += num_comments\n",
    "avg_show_comments = round(total_show_comments / len(show_posts))\n",
    "\n",
    "total_other_comments = 0\n",
    "for post in other_posts:\n",
    "    num_comments = int(post[4])\n",
    "    total_other_comments += num_comments\n",
    "avg_other_comments = round(total_other_comments / len(other_posts))\n",
    "\n",
    "string = 'Average comments for {list} posts is: {num}'\n",
    "print(string.format(list=\"Ask HN\", num=avg_ask_comments))\n",
    "print(string.format(list=\"Show HN\", num=avg_show_comments))\n",
    "print(string.format(list=\"other\", num=avg_other_comments))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see above, _Ask HN_ posts receive more comments than _Show HN_.\n",
    "\n",
    "Since ask posts are more likely to receive comments, we'll focus our remaining analysis just on these posts.\n",
    "\n",
    "Next, we'll determine if ask posts created at a certain time are more likely to attract comments. We'll use the following steps to perform this analysis:\n",
    "\n",
    "- Calculate the amount of ask posts created in each hour of the day, along with the number of comments received.\n",
    "- Calculate the average number of comments ask posts receive by hour created.\n",
    "\n",
    "We will start at the first step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "result_list = []\n",
    "\n",
    "for post in ask_posts:\n",
    "    created_at = post[6]\n",
    "    num_comments = int(post[4])\n",
    "    result_list.append([created_at, num_comments])\n",
    "\n",
    "counts_by_hour = {}\n",
    "comments_by_hour = {}\n",
    "\n",
    "for i in result_list:\n",
    "    hour = i[0]\n",
    "    comment = i[1]\n",
    "    hour = dt.datetime.strptime(hour, \"%m/%d/%Y %H:%M\")\n",
    "    hour = dt.datetime.strftime(hour, \"%H\")\n",
    "    if hour not in counts_by_hour:\n",
    "        counts_by_hour[hour] = 1\n",
    "        comments_by_hour[hour] = comment\n",
    "    if hour in counts_by_hour:\n",
    "        counts_by_hour[hour] += 1\n",
    "        comments_by_hour[hour] += comment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use both dictionaries created above, to calculate the average number of comments for posts created during each hour of the day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[['02', 11.122222222222222], ['01', 7.392226148409894], ['22', 8.78125], ['21', 8.67437379576108], ['19', 7.151898734177215], ['17', 9.438775510204081], ['15', 28.632148377125194], ['14', 9.673151750972762], ['13', 16.285393258426968], ['11', 8.942492012779553], ['10', 10.646643109540635], ['09', 7.058295964125561], ['07', 7.0], ['03', 7.922794117647059], ['23', 6.6773255813953485], ['20', 8.731898238747554], ['16', 7.7], ['08', 9.182170542635658], ['00', 7.546357615894039], ['18', 7.949593495934959], ['12', 12.361516034985423], ['04', 9.680327868852459], ['06', 6.757446808510639], ['05', 8.752380952380953]]\n"
     ]
    }
   ],
   "source": [
    "avg_by_hour = []\n",
    "for i in comments_by_hour:\n",
    "    counts = counts_by_hour[i]\n",
    "    comments = comments_by_hour[i]\n",
    "    average = comments/counts\n",
    "    avg_by_hour.append([i, average])\n",
    "\n",
    "print(avg_by_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can clean the data to make it easier to understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Top 5 Hours for Ask Posts Comments\n15:00: 28.63 average comments per post\n13:00: 16.29 average comments per post\n12:00: 12.36 average comments per post\n02:00: 11.12 average comments per post\n10:00: 10.65 average comments per post\n"
     ]
    }
   ],
   "source": [
    "swap_avg_by_hour = []\n",
    "\n",
    "for i in avg_by_hour: # Swap to order by average comments\n",
    "    swap_avg_by_hour.append([i[1],i[0]])\n",
    "sorted_swap = sorted(swap_avg_by_hour, reverse=True)\n",
    "\n",
    "print(\"Top 5 Hours for Ask Posts Comments\")\n",
    "string = \"{hour}: {average:.2f} average comments per post\"\n",
    "for i in sorted_swap[:5]:\n",
    "    average = i[0]\n",
    "    hour = i[1]\n",
    "    hour = dt.datetime.strptime(hour,\"%H\")\n",
    "    hour = dt.datetime.strftime(hour,\"%H:%M\")\n",
    "    print(string.format(string, hour=hour, average=average))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the top shown above, that creating a post between 15:00 and 16:59 will provide an average of +16 comments, up to 38. Creating the post at nigth, between 20:00 and 21:59 will result in 15 to 21 comments per post.\n",
    "\n",
    "There is an indication that Hacker News also fits nigth fans, because creating a post at 2 AM will provide an average of 23 comments."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python376jvsc74a57bd066501ffbd0a7f9b74feb0a7c5bd1c4d7f44fe125f79073c9f6a75e843de14fdf",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}